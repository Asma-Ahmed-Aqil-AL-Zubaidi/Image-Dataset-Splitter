{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoTjpK4PoBDEf8ovpMxTjD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asma-Ahmed-Aqil-AL-Zubaidi/Image-Dataset-Splitter/blob/main/Split_dataset_augmented_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split_dataset_augmented_images1_restorble_spilt"
      ],
      "metadata": {
        "id": "xRQz-XSYZU7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block of code splits a dataset of images into training, validation, and test sets.\n",
        "The split ratios are 70% for training, 20% for validation, and 10% for testing."
      ],
      "metadata": {
        "id": "HXn_sqKXFj_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Explanation\n",
        "\n",
        "1. **Importing Libraries**:\n",
        "    - `os`: Used for handling file and directory operations.\n",
        "    - `shutil`: Used for high-level file operations like copying and moving files.\n",
        "    - `random`: Used for shuffling the list of images.\n",
        "\n",
        "2. **Defining Paths**:\n",
        "    - `input_dir`: Path to the directory containing the original dataset of images.\n",
        "    - `output_dir`: Path to the directory where the split dataset will be stored.\n",
        "    - `train_dir`, `val_dir`, `test_dir`: Paths to the subdirectories for training, validation, and testing datasets.\n",
        "\n",
        "3. **Creating Directories**:\n",
        "    - A loop is used to create the `train_dir`, `val_dir`, and `test_dir` directories if they do not already exist.\n",
        "\n",
        "4. **Listing and Shuffling Images**:\n",
        "    - `all_images`: A list of all image filenames in the `input_dir`.\n",
        "    - `random.shuffle(all_images)`: Shuffles the list of image filenames to ensure random distribution.\n",
        "\n",
        "5. **Defining Split Points**:\n",
        "    - `train_split`: Index where the training set ends (70% of the dataset).\n",
        "    - `val_split`: Index where the validation set ends (90% of the dataset), leaving the last 10% for testing.\n",
        "\n",
        "6. **Splitting the Images**:\n",
        "    - `train_images`: List of image filenames for the training set.\n",
        "    - `val_images`: List of image filenames for the validation set.\n",
        "    - `test_images`: List of image filenames for the test set.\n",
        "\n",
        "7. **Moving Images**:\n",
        "    - The images are moved from the `input_dir` to the respective directories (`train_dir`, `val_dir`, `test_dir`) based on the splits.\n",
        "\n",
        "### Comments in the Code\n",
        "I added comments in the code to explain each step, providing clarity on the purpose of each block and line of code. The comments describe the process of defining paths, creating directories, shuffling and splitting the dataset, and moving files to the appropriate directories."
      ],
      "metadata": {
        "id": "l6yBJZwkFp4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0Jwphn9IKpZ",
        "outputId": "43dfa01d-bbc4-4c9a-c753-eb70304662d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os # For file and directory handling\n",
        "import shutil # For moving files\n",
        "import random # For shuffling the dataset"
      ],
      "metadata": {
        "id": "0O-HGOrYjiCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define paths for the input directory and the output directories for training, validation, and testing datasets"
      ],
      "metadata": {
        "id": "zkpzb67LEl6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = '/content/drive/MyDrive/A new/BK Non restorable final'\n",
        "output_dir = '/content/drive/MyDrive/dataset_update_augment/final N_update_spilt'\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'validation')\n",
        "test_dir = os.path.join(output_dir, 'test')"
      ],
      "metadata": {
        "id": "UW_VKXvNjiE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create directories if they do not exist"
      ],
      "metadata": {
        "id": "F38K05Z5Eumu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dir_path in [train_dir, val_dir, test_dir]:\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n"
      ],
      "metadata": {
        "id": "xLOVYxMTjiHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List all images in the input directory and shuffle them"
      ],
      "metadata": {
        "id": "jUFSd0KBE38o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data # Move images to the respective directories\n",
        "all_images = os.listdir(input_dir)\n",
        "random.shuffle(all_images)\n",
        "\n",
        "train_split = int(0.7 * len(all_images))\n",
        "val_split = int(0.9 * len(all_images))\n",
        "\n",
        "train_images = all_images[:train_split]\n",
        "val_images = all_images[train_split:val_split]\n",
        "test_images = all_images[val_split:]\n",
        "\n",
        "for image in train_images:\n",
        "    shutil.move(os.path.join(input_dir, image), train_dir)\n",
        "for image in val_images:\n",
        "    shutil.move(os.path.join(input_dir, image), val_dir)\n",
        "for image in test_images:\n",
        "    shutil.move(os.path.join(input_dir, image), test_dir)"
      ],
      "metadata": {
        "id": "YvQich9jjiKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split_dataset_augmented_images1_Non_restorble_spilt"
      ],
      "metadata": {
        "id": "7Aw3MW6mkKiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random"
      ],
      "metadata": {
        "id": "zMJM0g7wkMRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "input_dir = '/content/drive/MyDrive/dataset_update_augment/BK Non restorable final_update'\n",
        "output_dir = '/content/drive/MyDrive/dataset_update_augment/BK Non restorable final_update_split'\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'validation')\n",
        "test_dir = os.path.join(output_dir, 'test')"
      ],
      "metadata": {
        "id": "lmSDzFbHkPXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directories\n",
        "for dir_path in [train_dir, val_dir, test_dir]:\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)"
      ],
      "metadata": {
        "id": "0ONYnCRZkPbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "all_images = os.listdir(input_dir)\n",
        "random.shuffle(all_images)\n",
        "\n",
        "train_split = int(0.7 * len(all_images))\n",
        "val_split = int(0.9 * len(all_images))\n",
        "\n",
        "train_images = all_images[:train_split]\n",
        "val_images = all_images[train_split:val_split]\n",
        "test_images = all_images[val_split:]\n",
        "\n",
        "for image in train_images:\n",
        "    shutil.move(os.path.join(input_dir, image), train_dir)\n",
        "for image in val_images:\n",
        "    shutil.move(os.path.join(input_dir, image), val_dir)\n",
        "for image in test_images:\n",
        "    shutil.move(os.path.join(input_dir, image), test_dir)"
      ],
      "metadata": {
        "id": "wQ79JiFOkPfB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}